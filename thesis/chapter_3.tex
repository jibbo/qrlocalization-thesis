\chapter{Tools}
Developing this kind of systems is extremely complex, but it would be a lot harder without algorithms and libraries made by other people.
In order to make our solution clearer and honor their work, in the following paragraphs I will briefly describe all the tools used by the project.

\section{Language}
Every algorithm is implemented in C++ and all the used libraries bindings are also in the same language due to the fact that the system has to be performance driven. However, the proposed solution can be implemented with little modifications in other languages such as Java and Python, but, because we wanted to make the system run in embedded environments with limited resources such as a Beaglebone, C++ is a better fit.        

\section{Developing environment}
A common laptop with the following specifications has been used:
\begin{itemize}
  \item A 2,5 GHz Intel core i7 processor
  \item 8gb of RAM
  \item Integrated graphic card
\end{itemize}
This configuration is more powerful than the one which will be used in a real application. This is due to the fact that the rollator doesn't still have specific requirements but, instead, they are being deducted from experiments on the field. In addition, one of the purpose of the thesis is to proof that using this kind of systems is possible. Therefore, even if the system will not be able to run on a Beaglebone now, in a couple of years it should work without any problem.The chosen operating system is Slackware Linux -current (the current stable version is 14.1). This chose has been only made due to my familiarity with the OS but every GNU/Linux derivate which runs a version of the kernel later than version 2.6.32, because of the camera requirements, will be able to run the necessary software.
In fact the system has been tried on Ubuntu Linux 14.04 and openSUSE 13.1 without any problem, in addition the system has been tried on a 2012 Macbook Pro with OSX Mavericks and showed any sign of malfunction. 

\section{The camera}
In order to stream videos or take pictures a Playstation 3 Eye has been used.
This camera can operate at 120Hz with a resolution of 320x240 pixels but we, instead, preferred to operate at 640x480 pixels with a frequency of 60Hz because of the better resolution of the image which grant better working possibilities. The device is automatically recognized and used without issues if the version of the Linux Kernel installed is later than the version 2.6.32, previous versions needs a patch which is available online.
This camera was preferred because of its ability to stream uncompressed video directly \cite{pseyecompr}.

\begin{figure}[hbt]
    \vspace{2cm}
    \centering
    \includegraphics{img/pseye.png}
    \caption{The Playstation Eye}
\end{figure}
 
\newpage
\section{Libraries}

\subsection{OpenCV}
\begin{figure}[hbt]
    \centering
    \includegraphics[scale=0.5]{img/opencv.png}
    \caption{OpenCV's Logo}
\end{figure}
This is the library which empower almost any device with a camera to process images and videos allowing manipulations with consolidated algorithms created by universities and companies in order to let the developer focus on their own solution of a problem. In fact, OpenCV is the de facto standard for computer vision and it is wide-used in many Samsung Cameras for example, but also on Android smartphones and iOS devices. For our own purposes, the library free us of the burden to communicate with the webcam by giving APIs to open the streaming channel and taking pictures. 
\newline Used version: \textbf{2.4.9}

\subsection{ZBar}
\begin{figure}[hbt]
    \centering
    \includegraphics[scale=0.5]{img/zbar.png}
    \caption{OpenCV's Logo}
\end{figure}
The capability of decoding a QRCode is given by the ZBar library, which is open source and can decode also other kind of markers, for example: EAN-13/UPC-A, UPC-E, EAN-8 and Code 128.In addition, it is able to decode from a multitude of sources such as still images, raw intensity sensors and not only from video streams as the project shows. At the core of this possibility there is a streamlined C implementation of the \textbf{ISO/IEC 18004:2000} encoding/decoding standard which is perfect for embedded purposes.
The usage of its API is very simple because it abstracts all the hard work giving an Image scanner class which returns the list containing all the found symbols. Each symbol is basically what I transform into a class of QRCode with all the necessary data that our system needs.
\newline Used version: \textbf{0.10}.

\subsection{Eigen}

\begin{figure}[hbt]
    \centering
    \includegraphics[scale=0.5]{img/eigen.png}
    \caption{Eigen's Logo}
\end{figure}

This library provide abstractions and utilities for linear algebra such as numerical solvers but also matrices and other subject-related algorithms.
It is widely used by big companies such as Google too, for its own computer vision and machine learning algorithms.
The whole code is free-software because it is licensed with MPLv2 and it is based on C++ templating system, in this way the developer can use only the needed header file which allows reasonable compilation time and flexibility.\cite{eigeninfo}.
This library is actually used by the rectification algorithm, which is explained below, for its incredible matrix utilities.
\newline Used version: \textbf{3.2.1}.

\section{Other algorithms}

\subsection{Rectification}
The rectification process removes the perspective and corrects distortion inside a picture by creating a new virtual image which contains every pixel from the first on their right position, minus pixels which goes out of the boundaries.
The new position of each pixel is found using linear transformation and adjusted with the focal length of the camera.
In order to simplify the concept, the following pseudo-code shows the general algorithm.

\vspace{1cm}
\begin{lstlisting}
void rectification(constant Camera c_real, Camera c_virtual)
{
    setupVirtualCamera(c_virtual);
    image_x_distortion_correction = linear_transformation(c_real.image.center.x,c_virtual.image.center.x);
    image_y_distortion_correction = linear_transformation(c_real.image.center.y,c_virtual.image.center.y);
    focal_correction = focal_distance(c_real.focal,c_virtual.focal);
    for (int i = 0; i < c_real.image.pixels.length ; i++)
    {
		
		oldX =  c_real.image.pixels[i].x
		            +image_x_distortion_correction
		            +focal_correction;
		oldY =  c_real.image.pixels[i].y
		            +image_y_distortion_correction
		            +focal_correction;
		
		/* compute the focal distance in order to find the point */
		newY = computeY(oldX,c_real.focal,c_virtual.focal);
		newX = computeX(oldY,c_real.focal,c_virtual.focal);
		
		if( isOutOfVirtualBound(newX,newY)) then continue;
		
		writePixel(c_virtual.image,
		     c_real.image.pixels[i],newX,newY);
		     
    }

}
\end{lstlisting}

\begin{figure}[hbt] 
    \centering
    \caption{before and after rectification}
    \includegraphics{img/pseye.png}
\end{figure}




 
